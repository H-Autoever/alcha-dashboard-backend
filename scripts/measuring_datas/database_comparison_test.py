#!/usr/bin/env python3
"""
MongoDB vs TimescaleDB ì‹¤ì œ ì„±ëŠ¥ ê²€ì¦ í…ŒìŠ¤íŠ¸
- ë°ì´í„°ì— ê¸°ë°˜í•œ ì‹¤ì œ ì¸¡ì •ê°’ë§Œ í‘œì‹œ
- ì¢‹ê²Œ í¬ì¥í•˜ì§€ ì•Šê³  ì‹¤ì œ ê²°ê³¼ë§Œ ì œì‹œ
- Prometheus ë©”íŠ¸ë¦­ export ì§€ì›
"""

import sys
import os
import time
import math
import argparse
from pymongo import MongoClient
import psycopg2
from datetime import datetime, timedelta
import random
from prometheus_client import start_http_server, Gauge, Histogram

# MongoDB ì—°ê²°
MONGO_HOST = os.getenv("MONGO_HOST", "localhost")
MONGO_PORT = int(os.getenv("MONGO_PORT", "27017"))
MONGO_DB = os.getenv("MONGO_DB", "alcha_events")

# TimescaleDB ì—°ê²°
TIMESCALEDB_HOST = os.getenv("TIMESCALEDB_HOST", "localhost")
TIMESCALEDB_PORT = int(os.getenv("TIMESCALEDB_PORT", "5432"))
TIMESCALEDB_DB = os.getenv("TIMESCALEDB_DB", "alcha_events")
TIMESCALEDB_USER = os.getenv("TIMESCALEDB_USER", "alcha")
TIMESCALEDB_PASSWORD = os.getenv("TIMESCALEDB_PASSWORD", "alcha_password")

# Prometheus ë©”íŠ¸ë¦­ ì„¤ì •
METRICS_PORT = int(os.getenv("METRICS_PORT", "8000"))

# Prometheus ë©”íŠ¸ë¦­ ì •ì˜
db_write_records_per_second = Gauge(
    'db_write_records_per_second',
    'ì´ˆë‹¹ ì“°ê¸° ì²˜ë¦¬ ë ˆì½”ë“œ ìˆ˜',
    ['db', 'batch_size']
)

db_write_time_seconds = Histogram(
    'db_write_time_seconds',
    'ì“°ê¸° ì‘ì—… ì†Œìš” ì‹œê°„ (ì´ˆ)',
    ['db', 'batch_size'],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0]
)

db_stream_write_latency_seconds = Histogram(
    'db_stream_write_latency_seconds',
    'ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì“°ê¸° ì‹œ í‰ê·  ë ˆì½”ë“œ ì§€ì—° ì‹œê°„ (ì´ˆ)',
    ['db', 'mode'],
    buckets=[0.0005, 0.001, 0.005, 0.01, 0.02, 0.05, 0.1]
)

db_read_query_time_seconds = Histogram(
    'db_read_query_time_seconds',
    'ì½ê¸° ì¿¼ë¦¬ ì†Œìš” ì‹œê°„ (ì´ˆ)',
    ['db', 'query_type'],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
)

db_read_query_time_gauge = Gauge(
    'db_read_query_time_gauge_seconds',
    'ì½ê¸° ì¿¼ë¦¬ ì†Œìš” ì‹œê°„ (ì´ˆ) - ê²Œì´ì§€',
    ['db', 'query_type']
)


def _generate_vehicle_timestamp(base_time, index, interval_ms):
    """ìŠ¤íŠ¸ë¦¬ë° ìƒí™©ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìƒì„±."""
    step_ms = interval_ms if interval_ms and interval_ms > 0 else 1
    return (base_time + timedelta(milliseconds=index * step_ms)).strftime('%Y-%m-%dT%H:%M:%SZ')


def generate_vehicle_document(index, base_time, interval_ms, rng):
    """MongoDBìš© ì°¨ëŸ‰ í…”ë ˆë©”íŠ¸ë¦¬ ë„íë¨¼íŠ¸ ìƒì„±."""
    return {
        "vehicle_id": f"VHC-{rng.randint(1, 10):03d}",
        "vehicle_speed": rng.uniform(20, 120),
        "engine_rpm": rng.randint(800, 6000),
        "throttle_position": rng.uniform(0, 100),
        "timestamp": _generate_vehicle_timestamp(base_time, index, interval_ms),
        "sensor_data": {
            "temperature": rng.uniform(20, 100),
            "pressure": rng.uniform(10, 50),
            "additional_field_1": f"value_{index}",
            "additional_field_2": rng.randint(1, 1000),
            "nested_data": {
                "x": rng.uniform(-10, 10),
                "y": rng.uniform(-10, 10),
                "z": rng.uniform(8, 12)
            }
        }
    }


def generate_vehicle_tuple(index, base_time, interval_ms, rng):
    """TimescaleDBìš© ì°¨ëŸ‰ í…”ë ˆë©”íŠ¸ë¦¬ íŠœí”Œ ìƒì„±."""
    return (
        f"VHC-{rng.randint(1, 10):03d}",
        rng.uniform(20, 120),
        rng.randint(800, 6000),
        rng.uniform(0, 100),
        _generate_vehicle_timestamp(base_time, index, interval_ms)
    )


def _maybe_sleep_for_schedule(start_perf, index, interval_ms, jitter_ms, jitter_rng):
    """ìš”ì²­ëœ ê°„ê²©ì— ë§ì¶° sleep."""
    if (interval_ms is None or interval_ms <= 0) and (jitter_ms is None or jitter_ms <= 0):
        return

    base_ms = interval_ms if interval_ms and interval_ms > 0 else 0
    jitter_component = 0
    if jitter_ms and jitter_ms > 0:
        jitter_component = jitter_rng.uniform(-jitter_ms, jitter_ms)

    scheduled_ms = max(0.0, (index * base_ms) + jitter_component)
    target_time = start_perf + (scheduled_ms / 1000.0)
    now = time.perf_counter()
    sleep_duration = target_time - now
    if sleep_duration > 0:
        time.sleep(sleep_duration)


def _calculate_percentile(values, percentile):
    """ë‹¨ìˆœ ë°±ë¶„ìœ„ ê³„ì‚°."""
    if not values:
        return 0.0
    sorted_vals = sorted(values)
    k = (len(sorted_vals) - 1) * (percentile / 100.0)
    f = math.floor(k)
    c = math.ceil(k)
    if f == c:
        return sorted_vals[int(k)]
    d0 = sorted_vals[f] * (c - k)
    d1 = sorted_vals[c] * (k - f)
    return d0 + d1


def connect_mongodb():
    """MongoDB ì—°ê²°"""
    uri = f"mongodb://{MONGO_HOST}:{MONGO_PORT}/"
    client = MongoClient(uri)
    return client[MONGO_DB]

def connect_timescaledb():
    """TimescaleDB ì—°ê²°"""
    conn = psycopg2.connect(
        host=TIMESCALEDB_HOST,
        port=TIMESCALEDB_PORT,
        database=TIMESCALEDB_DB,
        user=TIMESCALEDB_USER,
        password=TIMESCALEDB_PASSWORD
    )
    return conn

def test_mongodb_write_performance(db_mongo):
    """í…ŒìŠ¤íŠ¸ 1: MongoDB ì“°ê¸° ì„±ëŠ¥ ê²€ì¦"""
    print("\n" + "="*80)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 1: MongoDB ì“°ê¸° ì„±ëŠ¥ ê²€ì¦")
    print("="*80)
    print("ëª©ì : MongoDBë¥¼ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ì´ìœ ì¸ ë¹ ë¥¸ ì“°ê¸° ì†ë„ ê²€ì¦")
    print("-"*80)
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    test_collection = "write_performance_test"
    db_mongo[test_collection].drop()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (432,000ê°œ ë ˆì½”ë“œ)
    test_data = []
    base_time = datetime(2025, 9, 23, 1, 54, 26)
    for i in range(432000):
        test_data.append({
            "vehicle_id": f"VHC-{random.randint(1, 10):03d}",
            "vehicle_speed": random.uniform(20, 120),
            "engine_rpm": random.randint(800, 6000),
            "throttle_position": random.uniform(0, 100),
            "timestamp": (base_time + timedelta(seconds=i)).strftime('%Y-%m-%dT%H:%M:%SZ'),
            "sensor_data": {
                "temperature": random.uniform(20, 100),
                "pressure": random.uniform(10, 50),
                "additional_field_1": f"value_{i}",
                "additional_field_2": random.randint(1, 1000),
                "nested_data": {
                    "x": random.uniform(-10, 10),
                    "y": random.uniform(-10, 10),
                    "z": random.uniform(8, 12)
                }
            }
        })
    
    # ë°°ì¹˜ ì“°ê¸° í…ŒìŠ¤íŠ¸
    batch_sizes = [1000, 10000, 50000, 100000]
    
    print(f"\ní…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê°œ ë ˆì½”ë“œ ì¤€ë¹„ ì™„ë£Œ")
    print(f"ë°°ì¹˜ í¬ê¸°ë³„ ì“°ê¸° ì„±ëŠ¥ ì¸¡ì •:\n")
    
    results = []
    for batch_size in batch_sizes:
        db_mongo[test_collection].drop()  # ì´ˆê¸°í™”
        batches = [test_data[i:i+batch_size] for i in range(0, len(test_data), batch_size)]
        
        total_time = 0
        total_inserted = 0
        
        print(f"  ë°°ì¹˜ í¬ê¸° {batch_size}:")
        print(f"    ë°°ì¹˜ ê°œìˆ˜: {len(batches)}ê°œ, ë°°ì¹˜ë‹¹ í‰ê·  ë ˆì½”ë“œ: {len(test_data) // len(batches)}ê°œ")
        
        for batch_idx, batch in enumerate(batches):
            start = time.time()
            result = db_mongo[test_collection].insert_many(batch)
            elapsed = time.time() - start
            total_time += elapsed
            total_inserted += len(result.inserted_ids)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ (í° ë°°ì¹˜ì˜ ê²½ìš°)
            if batch_size >= 10000:
                if (batch_idx + 1) % max(1, len(batches) // 20) == 0 or (batch_idx + 1) == len(batches):
                    print(f"      ì§„í–‰: {batch_idx + 1}/{len(batches)} ë°°ì¹˜ ì™„ë£Œ... ({batch_idx * batch_size}/{len(test_data)} ë ˆì½”ë“œ)")
        
        records_per_second = total_inserted / total_time
        avg_time_per_batch = total_time / len(batches)
        
        results.append({
            'batch_size': batch_size,
            'total_records': total_inserted,
            'total_time': total_time,
            'records_per_second': records_per_second,
            'avg_time_per_batch': avg_time_per_batch
        })
        
        print(f"    ê²°ê³¼:")
        print(f"      - ì´ ë ˆì½”ë“œ: {total_inserted}ê°œ")
        print(f"      - ì´ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time*1000:.2f}ms)")
        print(f"      - ì´ˆë‹¹ ì²˜ë¦¬: {records_per_second:.0f} ë ˆì½”ë“œ/ì´ˆ")
        print(f"      - ë°°ì¹˜ë‹¹ í‰ê· : {avg_time_per_batch:.2f}ì´ˆ ({avg_time_per_batch*1000:.2f}ms)")
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        db_write_records_per_second.labels(db='mongodb', batch_size=str(batch_size)).set(records_per_second)
        db_write_time_seconds.labels(db='mongodb', batch_size=str(batch_size)).observe(total_time)
    
    # ìµœì  ë°°ì¹˜ í¬ê¸°
    best = max(results, key=lambda x: x['records_per_second'])
    print(f"\nìµœì  ì„±ëŠ¥:")
    print(f"  ë°°ì¹˜ í¬ê¸°: {best['batch_size']}")
    print(f"  ì´ˆë‹¹ ì²˜ë¦¬: {best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    
    return results

def test_timescaledb_write_performance(conn_tsdb):
    """í…ŒìŠ¤íŠ¸ 2: TimescaleDB ì“°ê¸° ì„±ëŠ¥ ê²€ì¦"""
    print("\n" + "="*80)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 2: TimescaleDB ì“°ê¸° ì„±ëŠ¥ ê²€ì¦")
    print("="*80)
    print("ëª©ì : TimescaleDBì˜ ì“°ê¸° ì„±ëŠ¥ ì¸¡ì • ë° MongoDBì™€ ë¹„êµ")
    print("-"*80)
    
    cursor = conn_tsdb.cursor()
    
    # í…ŒìŠ¤íŠ¸ í…Œì´ë¸” ìƒì„±
    cursor.execute("""
        DROP TABLE IF EXISTS write_performance_test CASCADE;
    """)
    cursor.execute("""
        CREATE TABLE write_performance_test (
            vehicle_id VARCHAR(50) NOT NULL,
            vehicle_speed FLOAT,
            engine_rpm INTEGER,
            throttle_position FLOAT,
            timestamp TIMESTAMPTZ NOT NULL
        );
    """)
    cursor.execute("SELECT create_hypertable('write_performance_test', 'timestamp', if_not_exists => TRUE);")
    conn_tsdb.commit()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (432,000ê°œ ë ˆì½”ë“œ)
    test_data = []
    base_time = datetime(2025, 9, 23, 1, 54, 26)
    for i in range(432000):
        test_data.append((
            f"VHC-{random.randint(1, 10):03d}",
            random.uniform(20, 120),
            random.randint(800, 6000),
            random.uniform(0, 100),
            (base_time + timedelta(seconds=i)).strftime('%Y-%m-%dT%H:%M:%SZ')
        ))
    
    # ë°°ì¹˜ ì“°ê¸° í…ŒìŠ¤íŠ¸
    batch_sizes = [1000, 10000, 50000, 100000]
    
    print(f"\ní…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê°œ ë ˆì½”ë“œ ì¤€ë¹„ ì™„ë£Œ")
    print(f"ë°°ì¹˜ í¬ê¸°ë³„ ì“°ê¸° ì„±ëŠ¥ ì¸¡ì •:\n")
    
    results = []
    for batch_size in batch_sizes:
        cursor.execute("DELETE FROM write_performance_test;")
        conn_tsdb.commit()
        
        batches = [test_data[i:i+batch_size] for i in range(0, len(test_data), batch_size)]
        
        total_time = 0
        total_inserted = 0
        
        print(f"  ë°°ì¹˜ í¬ê¸° {batch_size}:")
        print(f"    ë°°ì¹˜ ê°œìˆ˜: {len(batches)}ê°œ, ë°°ì¹˜ë‹¹ í‰ê·  ë ˆì½”ë“œ: {len(test_data) // len(batches)}ê°œ")
        
        for batch_idx, batch in enumerate(batches):
            start = time.time()
            cursor.executemany("""
                INSERT INTO write_performance_test (vehicle_id, vehicle_speed, engine_rpm, throttle_position, timestamp)
                VALUES (%s, %s, %s, %s, %s)
            """, batch)
            conn_tsdb.commit()
            elapsed = time.time() - start
            total_time += elapsed
            total_inserted += len(batch)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ (í° ë°°ì¹˜ì˜ ê²½ìš°)
            if batch_size >= 10000:
                if (batch_idx + 1) % max(1, len(batches) // 20) == 0 or (batch_idx + 1) == len(batches):
                    print(f"      ì§„í–‰: {batch_idx + 1}/{len(batches)} ë°°ì¹˜ ì™„ë£Œ... ({batch_idx * batch_size}/{len(test_data)} ë ˆì½”ë“œ)")
        
        records_per_second = total_inserted / total_time
        avg_time_per_batch = total_time / len(batches)
        
        results.append({
            'batch_size': batch_size,
            'total_records': total_inserted,
            'total_time': total_time,
            'records_per_second': records_per_second,
            'avg_time_per_batch': avg_time_per_batch
        })
        
        print(f"    ê²°ê³¼:")
        print(f"      - ì´ ë ˆì½”ë“œ: {total_inserted}ê°œ")
        print(f"      - ì´ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time*1000:.2f}ms)")
        print(f"      - ì´ˆë‹¹ ì²˜ë¦¬: {records_per_second:.0f} ë ˆì½”ë“œ/ì´ˆ")
        print(f"      - ë°°ì¹˜ë‹¹ í‰ê· : {avg_time_per_batch:.2f}ì´ˆ ({avg_time_per_batch*1000:.2f}ms)")
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        db_write_records_per_second.labels(db='timescaledb', batch_size=str(batch_size)).set(records_per_second)
        db_write_time_seconds.labels(db='timescaledb', batch_size=str(batch_size)).observe(total_time)
    
    # ìµœì  ë°°ì¹˜ í¬ê¸°
    best = max(results, key=lambda x: x['records_per_second'])
    print(f"\nìµœì  ì„±ëŠ¥:")
    print(f"  ë°°ì¹˜ í¬ê¸°: {best['batch_size']}")
    print(f"  ì´ˆë‹¹ ì²˜ë¦¬: {best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    
    cursor.close()
    return results


def test_mongodb_streaming_write_performance(
    db_mongo,
    total_records=100000,
    interval_ms=0,
    jitter_ms=0,
    buffer_size=1,
    progress_every=5000
):
    """MongoDB ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì“°ê¸° ì„±ëŠ¥ ê²€ì¦."""
    print("\n" + "="*80)
    print("ğŸš€ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸: MongoDB ì‹¤ì‹œê°„ ì“°ê¸° ì„±ëŠ¥ ê²€ì¦")
    print("="*80)
    print("ëª©ì : ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì‚½ì… ì‹œ MongoDB ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •")
    print("-"*80)

    collection = db_mongo["stream_write_performance_test"]
    collection.drop()

    rng = random.Random(42)
    jitter_rng = random.Random(4242)
    base_time = datetime.utcnow()

    buffer = []
    inserted = 0
    flush_count = 0
    per_record_latencies = []
    mode_label = f"stream_buffer_{buffer_size}"

    start_perf = time.perf_counter()
    start_wall = datetime.utcnow()

    for index in range(total_records):
        _maybe_sleep_for_schedule(start_perf, index, interval_ms, jitter_ms, jitter_rng)

        buffer.append(generate_vehicle_document(index, base_time, interval_ms, rng))

        if len(buffer) >= buffer_size:
            flush_start = time.perf_counter()
            if buffer_size == 1:
                collection.insert_one(buffer[0])
            else:
                collection.insert_many(buffer, ordered=False)
            flush_elapsed = time.perf_counter() - flush_start

            per_record_latency = flush_elapsed / len(buffer)
            per_record_latencies.extend([per_record_latency] * len(buffer))
            db_stream_write_latency_seconds.labels(db='mongodb', mode=mode_label).observe(per_record_latency)

            inserted += len(buffer)
            flush_count += 1
            buffer.clear()

            if progress_every and inserted % progress_every == 0:
                print(f"  ì§„í–‰ ìƒí™©: {inserted}/{total_records} ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ")

    if buffer:
        flush_start = time.perf_counter()
        if len(buffer) == 1:
            collection.insert_one(buffer[0])
        else:
            collection.insert_many(buffer, ordered=False)
        flush_elapsed = time.perf_counter() - flush_start
        per_record_latency = flush_elapsed / len(buffer)
        per_record_latencies.extend([per_record_latency] * len(buffer))
        db_stream_write_latency_seconds.labels(db='mongodb', mode=mode_label).observe(per_record_latency)
        inserted += len(buffer)
        flush_count += 1
        buffer.clear()

    total_elapsed = time.perf_counter() - start_perf
    records_per_second = inserted / total_elapsed if total_elapsed > 0 else 0
    avg_latency = sum(per_record_latencies) / len(per_record_latencies) if per_record_latencies else 0
    p95_latency = _calculate_percentile(per_record_latencies, 95)

    print(f"\ní…ŒìŠ¤íŠ¸ ìš”ì•½ (MongoDB):")
    print(f"  - ì´ ì‚½ì… ë ˆì½”ë“œ: {inserted}ê°œ")
    print(f"  - ì´ ê²½ê³¼ ì‹œê°„: {total_elapsed:.2f}ì´ˆ")
    print(f"  - ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰: {records_per_second:.2f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"  - í‰ê·  ë ˆì½”ë“œ ì§€ì—°: {avg_latency*1000:.3f}ms")
    print(f"  - 95í¼ì„¼íƒ€ì¼ ì§€ì—°: {p95_latency*1000:.3f}ms")
    print(f"  - ë²„í¼ í¬ê¸°: {buffer_size}")
    print(f"  - ì‹œì‘ ì‹œê°: {start_wall.isoformat()}Z")

    db_write_records_per_second.labels(db='mongodb', batch_size=mode_label).set(records_per_second)
    db_write_time_seconds.labels(db='mongodb', batch_size=mode_label).observe(total_elapsed)

    return {
        'mode': mode_label,
        'total_records': inserted,
        'total_time': total_elapsed,
        'records_per_second': records_per_second,
        'avg_latency': avg_latency,
        'p95_latency': p95_latency,
        'flush_count': flush_count,
        'interval_ms': interval_ms,
        'jitter_ms': jitter_ms,
        'buffer_size': buffer_size
    }


def test_timescaledb_streaming_write_performance(
    conn_tsdb,
    total_records=100000,
    interval_ms=0,
    jitter_ms=0,
    buffer_size=1,
    commit_size=None,
    progress_every=5000
):
    """TimescaleDB ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì“°ê¸° ì„±ëŠ¥ ê²€ì¦."""
    print("\n" + "="*80)
    print("ğŸš€ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸: TimescaleDB ì‹¤ì‹œê°„ ì“°ê¸° ì„±ëŠ¥ ê²€ì¦")
    print("="*80)
    print("ëª©ì : ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì‚½ì… ì‹œ TimescaleDB ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •")
    print("-"*80)

    commit_size = commit_size or buffer_size
    cursor = conn_tsdb.cursor()

    cursor.execute("""
        DROP TABLE IF EXISTS stream_write_performance_test CASCADE;
    """)
    cursor.execute("""
        CREATE TABLE stream_write_performance_test (
            vehicle_id VARCHAR(50) NOT NULL,
            vehicle_speed FLOAT,
            engine_rpm INTEGER,
            throttle_position FLOAT,
            timestamp TIMESTAMPTZ NOT NULL
        );
    """)
    cursor.execute("SELECT create_hypertable('stream_write_performance_test', 'timestamp', if_not_exists => TRUE);")
    conn_tsdb.commit()

    rng = random.Random(42)
    jitter_rng = random.Random(4242)
    base_time = datetime.utcnow()

    buffer = []
    pending_commit = 0
    inserted = 0
    flush_count = 0
    per_record_latencies = []
    mode_label = f"stream_buffer_{buffer_size}_commit_{commit_size}"

    start_perf = time.perf_counter()
    start_wall = datetime.utcnow()

    insert_sql = """
        INSERT INTO stream_write_performance_test (vehicle_id, vehicle_speed, engine_rpm, throttle_position, timestamp)
        VALUES (%s, %s, %s, %s, %s)
    """

    for index in range(total_records):
        _maybe_sleep_for_schedule(start_perf, index, interval_ms, jitter_ms, jitter_rng)

        buffer.append(generate_vehicle_tuple(index, base_time, interval_ms, rng))

        if len(buffer) >= buffer_size:
            flush_start = time.perf_counter()
            cursor.executemany(insert_sql, buffer)
            flush_elapsed = time.perf_counter() - flush_start

            pending_commit += len(buffer)
            per_record_latency = flush_elapsed / len(buffer)
            per_record_latencies.extend([per_record_latency] * len(buffer))
            db_stream_write_latency_seconds.labels(db='timescaledb', mode=mode_label).observe(per_record_latency)

            inserted += len(buffer)
            flush_count += 1
            buffer.clear()

            if pending_commit >= commit_size:
                conn_tsdb.commit()
                pending_commit = 0

            if progress_every and inserted % progress_every == 0:
                print(f"  ì§„í–‰ ìƒí™©: {inserted}/{total_records} ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ")

    if buffer:
        flush_start = time.perf_counter()
        cursor.executemany(insert_sql, buffer)
        flush_elapsed = time.perf_counter() - flush_start
        per_record_latency = flush_elapsed / len(buffer)
        per_record_latencies.extend([per_record_latency] * len(buffer))
        db_stream_write_latency_seconds.labels(db='timescaledb', mode=mode_label).observe(per_record_latency)

        inserted += len(buffer)
        flush_count += 1
        pending_commit += len(buffer)
        buffer.clear()

    if pending_commit > 0:
        conn_tsdb.commit()

    total_elapsed = time.perf_counter() - start_perf
    records_per_second = inserted / total_elapsed if total_elapsed > 0 else 0
    avg_latency = sum(per_record_latencies) / len(per_record_latencies) if per_record_latencies else 0
    p95_latency = _calculate_percentile(per_record_latencies, 95)

    print(f"\ní…ŒìŠ¤íŠ¸ ìš”ì•½ (TimescaleDB):")
    print(f"  - ì´ ì‚½ì… ë ˆì½”ë“œ: {inserted}ê°œ")
    print(f"  - ì´ ê²½ê³¼ ì‹œê°„: {total_elapsed:.2f}ì´ˆ")
    print(f"  - ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰: {records_per_second:.2f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"  - í‰ê·  ë ˆì½”ë“œ ì§€ì—°: {avg_latency*1000:.3f}ms")
    print(f"  - 95í¼ì„¼íƒ€ì¼ ì§€ì—°: {p95_latency*1000:.3f}ms")
    print(f"  - ë²„í¼ í¬ê¸°: {buffer_size}, ì»¤ë°‹ ê°„ê²©: {commit_size}")
    print(f"  - ì‹œì‘ ì‹œê°: {start_wall.isoformat()}Z")

    db_write_records_per_second.labels(db='timescaledb', batch_size=mode_label).set(records_per_second)
    db_write_time_seconds.labels(db='timescaledb', batch_size=mode_label).observe(total_elapsed)

    cursor.close()

    return {
        'mode': mode_label,
        'total_records': inserted,
        'total_time': total_elapsed,
        'records_per_second': records_per_second,
        'avg_latency': avg_latency,
        'p95_latency': p95_latency,
        'flush_count': flush_count,
        'interval_ms': interval_ms,
        'jitter_ms': jitter_ms,
        'buffer_size': buffer_size,
        'commit_size': commit_size
    }

def test_timescaledb_time_series_query_performance(conn_tsdb):
    """í…ŒìŠ¤íŠ¸ 3: TimescaleDB ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦"""
    print("\n" + "="*80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ 3: TimescaleDB ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦")
    print("="*80)
    print("ëª©ì : TimescaleDBë¥¼ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ì´ìœ ì¸ ì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥ ê²€ì¦")
    print("-"*80)
    
    cursor = conn_tsdb.cursor()
    
    # ì‹¤ì œ ë°ì´í„° ê¸°ì¤€ í…ŒìŠ¤íŠ¸
    vehicle_ids = ["VHC-001", "VHC-002", "VHC-003"]
    
    tests = [
        {
            "name": "ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)",
            "query": """
                SELECT vehicle_id, vehicle_speed, engine_rpm, throttle_position, timestamp
                FROM vehicle_telemetry
                WHERE vehicle_id = %s 
                  AND timestamp >= %s 
                  AND timestamp <= %s
                ORDER BY timestamp ASC
            """,
            "params": lambda vid: (vid, "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        },
        {
            "name": "ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)",
            "query": """
                SELECT 
                    COUNT(*) as count,
                    AVG(vehicle_speed) as avg_speed,
                    MAX(vehicle_speed) as max_speed,
                    MIN(vehicle_speed) as min_speed,
                    AVG(engine_rpm) as avg_rpm,
                    MAX(engine_rpm) as max_rpm,
                    MIN(engine_rpm) as min_rpm
                FROM vehicle_telemetry
                WHERE vehicle_id = %s 
                  AND timestamp >= %s 
                  AND timestamp <= %s
            """,
            "params": lambda vid: (vid, "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        },
        {
            "name": "ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)",
            "query": """
                SELECT 
                    time_bucket('10 minutes', timestamp) as bucket,
                    AVG(vehicle_speed) as avg_speed,
                    COUNT(*) as count
                FROM vehicle_telemetry
                WHERE vehicle_id = %s 
                  AND timestamp >= %s 
                  AND timestamp <= %s
                GROUP BY bucket
                ORDER BY bucket ASC
            """,
            "params": lambda vid: (vid, "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        },
        {
            "name": "ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (1ë¶„ ë‹¨ìœ„)",
            "query": """
                SELECT 
                    time_bucket('1 minute', timestamp) as bucket,
                    AVG(vehicle_speed) as avg_speed,
                    COUNT(*) as count
                FROM vehicle_telemetry
                WHERE vehicle_id = %s 
                  AND timestamp >= %s 
                  AND timestamp <= %s
                GROUP BY bucket
                ORDER BY bucket ASC
            """,
            "params": lambda vid: (vid, "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        },
        {
            "name": "ë³µì¡í•œ ì‹œê°„ ë²”ìœ„ ì§‘ê³„ (ë‹¤ì¤‘ ì°¨ëŸ‰)",
            "query": """
                SELECT 
                    vehicle_id,
                    time_bucket('5 minutes', timestamp) as bucket,
                    AVG(vehicle_speed) as avg_speed,
                    MAX(vehicle_speed) as max_speed,
                    COUNT(*) as count
                FROM vehicle_telemetry
                WHERE vehicle_id IN (%s, %s, %s)
                  AND timestamp >= %s 
                  AND timestamp <= %s
                GROUP BY vehicle_id, bucket
                ORDER BY vehicle_id, bucket ASC
            """,
            "params": lambda vid: ("VHC-001", "VHC-002", "VHC-003", "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        }
    ]
    
    print(f"\nì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • (ê° í…ŒìŠ¤íŠ¸ 10íšŒ ë°˜ë³µ, í‰ê· ê°’ ì‚¬ìš©):\n")
    
    results = []
    for test in tests:
        times = []
        for _ in range(10):
            start = time.time()
            if "vehicle_id IN" in test["query"]:
                cursor.execute(test["query"], test["params"](None))
            else:
                cursor.execute(test["query"], test["params"]("VHC-001"))
            cursor.fetchall()
            times.append(time.time() - start)
        
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        # ê²°ê³¼ ê°œìˆ˜ í™•ì¸ (í•œ ë²ˆë§Œ ì‹¤í–‰)
        if "vehicle_id IN" in test["query"]:
            cursor.execute(test["query"], test["params"](None))
        else:
            cursor.execute(test["query"], test["params"]("VHC-001"))
        result_count = len(cursor.fetchall())
        
        results.append({
            'name': test['name'],
            'avg_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'result_count': result_count
        })
        
        print(f"  {test['name']}:")
        print(f"    - í‰ê·  ì‹œê°„: {avg_time*1000:.2f}ms")
        print(f"    - ìµœì†Œ ì‹œê°„: {min_time*1000:.2f}ms")
        print(f"    - ìµœëŒ€ ì‹œê°„: {max_time*1000:.2f}ms")
        print(f"    - ê²°ê³¼ ê°œìˆ˜: {result_count}ê°œ")
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        query_type_map = {
            'ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)': 'time_range',
            'ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)': 'aggregation',
            'ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)': 'time_grouping_10min',
            'ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (1ë¶„ ë‹¨ìœ„)': 'time_grouping_1min',
            'ë³µì¡í•œ ì‹œê°„ ë²”ìœ„ ì§‘ê³„ (ë‹¤ì¤‘ ì°¨ëŸ‰)': 'multi_vehicle_aggregation'
        }
        query_type = query_type_map.get(test['name'], 'unknown')
        
        for time_val in times:
            db_read_query_time_seconds.labels(db='timescaledb', query_type=query_type).observe(time_val)
        db_read_query_time_gauge.labels(db='timescaledb', query_type=query_type).set(avg_time)
    
    cursor.close()
    return results

def test_mongodb_time_series_query_performance(db_mongo):
    """í…ŒìŠ¤íŠ¸ 4: MongoDB ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦ (ë¹„êµìš©)"""
    print("\n" + "="*80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ 4: MongoDB ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦ (ë¹„êµìš©)")
    print("="*80)
    print("ëª©ì : MongoDBì˜ ì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • ë° TimescaleDBì™€ ë¹„êµ")
    print("-"*80)
    
    vehicle_id = "VHC-001"
    start_time = "2025-09-23T01:54:26Z"
    end_time = "2025-09-24T17:54:26Z"  # 40ì‹œê°„ í›„
    
    tests = [
        {
            "name": "ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)",
            "operation": lambda: list(db_mongo["realtime-storage-data"].find({
                "vehicle_id": vehicle_id,
                "timestamp": {"$gte": start_time, "$lte": end_time}
            }).sort("timestamp", 1))
        },
        {
            "name": "ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)",
            "operation": lambda: list(db_mongo["realtime-storage-data"].aggregate([
                {"$match": {
                    "vehicle_id": vehicle_id,
                    "timestamp": {"$gte": start_time, "$lte": end_time}
                }},
                {"$group": {
                    "_id": None,
                    "avg_speed": {"$avg": "$vehicle_speed"},
                    "max_speed": {"$max": "$vehicle_speed"},
                    "min_speed": {"$min": "$vehicle_speed"},
                    "avg_rpm": {"$avg": "$engine_rpm"},
                    "max_rpm": {"$max": "$engine_rpm"},
                    "min_rpm": {"$min": "$engine_rpm"},
                    "count": {"$sum": 1}
                }}
            ]))
        },
        {
            "name": "ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)",
            "operation": lambda: list(db_mongo["realtime-storage-data"].aggregate([
                {"$match": {
                    "vehicle_id": vehicle_id,
                    "timestamp": {"$gte": start_time, "$lte": end_time}
                }},
                {"$addFields": {
                    "timestamp_iso": {"$dateFromString": {"dateString": "$timestamp"}}
                }},
                {"$group": {
                    "_id": {
                        "$dateTrunc": {
                            "date": "$timestamp_iso",
                            "unit": "minute",
                            "binSize": 10
                        }
                    },
                    "avg_speed": {"$avg": "$vehicle_speed"},
                    "count": {"$sum": 1}
                }},
                {"$sort": {"_id": 1}}
            ]))
        }
    ]
    
    print(f"\nì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • (ê° í…ŒìŠ¤íŠ¸ 10íšŒ ë°˜ë³µ, í‰ê· ê°’ ì‚¬ìš©):\n")
    
    results = []
    for test in tests:
        times = []
        for _ in range(10):
            start = time.time()
            result = test["operation"]()
            times.append(time.time() - start)
        
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        result_count = len(result)
        
        results.append({
            'name': test['name'],
            'avg_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'result_count': result_count
        })
        
        print(f"  {test['name']}:")
        print(f"    - í‰ê·  ì‹œê°„: {avg_time*1000:.2f}ms")
        print(f"    - ìµœì†Œ ì‹œê°„: {min_time*1000:.2f}ms")
        print(f"    - ìµœëŒ€ ì‹œê°„: {max_time*1000:.2f}ms")
        print(f"    - ê²°ê³¼ ê°œìˆ˜: {result_count}ê°œ")
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        query_type_map = {
            'ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)': 'time_range',
            'ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)': 'aggregation',
            'ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)': 'time_grouping_10min'
        }
        query_type = query_type_map.get(test['name'], 'unknown')
        
        for time_val in times:
            db_read_query_time_seconds.labels(db='mongodb', query_type=query_type).observe(time_val)
        db_read_query_time_gauge.labels(db='mongodb', query_type=query_type).set(avg_time)
    
    return results

def print_comparison_summary(mongo_write, tsdb_write, tsdb_read, mongo_read):
    """ë¹„êµ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“Š ì¢…í•© ë¹„êµ ìš”ì•½")
    print("="*80)
    
    # ì“°ê¸° ì„±ëŠ¥ ë¹„êµ
    mongo_best = max(mongo_write, key=lambda x: x['records_per_second'])
    tsdb_best = max(tsdb_write, key=lambda x: x['records_per_second'])
    
    print(f"\n1. ì“°ê¸° ì„±ëŠ¥ (ìµœì  ë°°ì¹˜ í¬ê¸° ê¸°ì¤€):")
    print(f"   MongoDB:")
    print(f"     - ì´ˆë‹¹ ì²˜ë¦¬: {mongo_best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"     - ë°°ì¹˜ í¬ê¸°: {mongo_best['batch_size']}")
    print(f"   TimescaleDB:")
    print(f"     - ì´ˆë‹¹ ì²˜ë¦¬: {tsdb_best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"     - ë°°ì¹˜ í¬ê¸°: {tsdb_best['batch_size']}")
    
    if mongo_best['records_per_second'] > tsdb_best['records_per_second']:
        diff = (mongo_best['records_per_second'] / tsdb_best['records_per_second'] - 1) * 100
        print(f"   â†’ MongoDBê°€ {diff:.1f}% ë¹ ë¦„")
    else:
        diff = (tsdb_best['records_per_second'] / mongo_best['records_per_second'] - 1) * 100
        print(f"   â†’ TimescaleDBê°€ {diff:.1f}% ë¹ ë¦„")
    
    # ì½ê¸° ì„±ëŠ¥ ë¹„êµ (ë™ì¼í•œ ì¿¼ë¦¬ë§Œ ë¹„êµ)
    print(f"\n2. ì‹œê³„ì—´ ì½ê¸° ì„±ëŠ¥ (í‰ê· ê°’ ê¸°ì¤€):")
    
    common_tests = [
        ("ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬", "ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)"),
        ("ì§‘ê³„ ì¿¼ë¦¬", "ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)"),
        ("ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™”", "ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)")
    ]
    
    for test_name, mongo_key in common_tests:
        mongo_test = next((t for t in mongo_read if mongo_key in t['name']), None)
        tsdb_test = next((t for t in tsdb_read if test_name in t['name'] or mongo_key in t['name']), None)
        
        if mongo_test and tsdb_test:
            print(f"\n   {test_name}:")
            print(f"     - MongoDB: {mongo_test['avg_time']*1000:.2f}ms")
            print(f"     - TimescaleDB: {tsdb_test['avg_time']*1000:.2f}ms")
            if mongo_test['avg_time'] > tsdb_test['avg_time']:
                diff = (mongo_test['avg_time'] / tsdb_test['avg_time'] - 1) * 100
                print(f"     â†’ TimescaleDBê°€ {diff:.1f}% ë¹ ë¦„")
            else:
                diff = (tsdb_test['avg_time'] / mongo_test['avg_time'] - 1) * 100
                print(f"     â†’ MongoDBê°€ {diff:.1f}% ë¹ ë¦„")
    
    print(f"\n3. ê²°ë¡ :")
    print(f"   - MongoDB ì“°ê¸°: {mongo_best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"   - TimescaleDB ì“°ê¸°: {tsdb_best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"   - ì‹œê³„ì—´ ì¿¼ë¦¬: ì‹¤ì œ ì¸¡ì •ê°’ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨")


def print_streaming_comparison_summary(mongo_stream, tsdb_stream):
    """ìŠ¤íŠ¸ë¦¬ë° ì“°ê¸° ë¹„êµ ìš”ì•½ ì¶œë ¥."""
    print("\n" + "="*80)
    print("ğŸ“Š ìŠ¤íŠ¸ë¦¬ë° ì“°ê¸° ë¹„êµ ìš”ì•½")
    print("="*80)

    print("\nMongoDB:")
    print(f"  - ëª¨ë“œ: {mongo_stream['mode']}")
    print(f"  - ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰: {mongo_stream['records_per_second']:.2f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"  - í‰ê·  ì§€ì—°: {mongo_stream['avg_latency']*1000:.3f}ms")
    print(f"  - 95í¼ì„¼íƒ€ì¼ ì§€ì—°: {mongo_stream['p95_latency']*1000:.3f}ms")

    print("\nTimescaleDB:")
    print(f"  - ëª¨ë“œ: {tsdb_stream['mode']}")
    print(f"  - ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰: {tsdb_stream['records_per_second']:.2f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"  - í‰ê·  ì§€ì—°: {tsdb_stream['avg_latency']*1000:.3f}ms")
    print(f"  - 95í¼ì„¼íƒ€ì¼ ì§€ì—°: {tsdb_stream['p95_latency']*1000:.3f}ms")

    throughput_ratio = 0.0
    if tsdb_stream['records_per_second'] > 0:
        throughput_ratio = mongo_stream['records_per_second'] / tsdb_stream['records_per_second']

    print("\nê²°ë¡ :")
    if throughput_ratio == 0:
        print("  - TimescaleDB throughputê°€ 0ì— ê°€ê¹Œì›Œ ë¹„êµ ë¶ˆê°€")
    elif throughput_ratio >= 1:
        diff = (throughput_ratio - 1) * 100
        print(f"  - MongoDBê°€ {diff:.1f}% ë” ë¹ ë¥¸ ìŠ¤íŠ¸ë¦¬ë° ì“°ê¸° ì²˜ë¦¬ëŸ‰")
    else:
        diff = ((1 / throughput_ratio) - 1) * 100
        print(f"  - TimescaleDBê°€ {diff:.1f}% ë” ë¹ ë¥¸ ìŠ¤íŠ¸ë¦¬ë° ì“°ê¸° ì²˜ë¦¬ëŸ‰")

    print(f"  - í‰ê·  ì§€ì—° ë¹„êµ: MongoDB {mongo_stream['avg_latency']*1000:.3f}ms vs TimescaleDB {tsdb_stream['avg_latency']*1000:.3f}ms")
    print("="*80)


def parse_arguments():
    """CLI ì¸ì íŒŒì‹±."""
    parser = argparse.ArgumentParser(description="MongoDB vs TimescaleDB ì„±ëŠ¥ ì¸¡ì • ë„êµ¬")
    parser.add_argument(
        "--mode",
        choices=["batch", "stream", "all"],
        default="batch",
        help="ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì„ íƒ (ê¸°ë³¸ê°’: batch)"
    )
    parser.add_argument(
        "--stream-total-records",
        type=int,
        default=50000,
        help="ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì‹œ ì‚½ì…í•  ì´ ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 50,000)"
    )
    parser.add_argument(
        "--stream-interval-ms",
        type=float,
        default=0,
        help="ê° ë ˆì½”ë“œ ê°„ê²©(ms). 0ì´ë©´ ê°€ëŠ¥í•œ ë¹ ë¥´ê²Œ ì‚½ì… (ê¸°ë³¸ê°’: 0)"
    )
    parser.add_argument(
        "--stream-jitter-ms",
        type=float,
        default=0,
        help="ê°„ê²©ì— ì¶”ê°€ë  ì§€í„° ë²”ìœ„(ms) (ê¸°ë³¸ê°’: 0)"
    )
    parser.add_argument(
        "--stream-buffer-size",
        type=int,
        default=1,
        help="ìŠ¤íŠ¸ë¦¬ë° ì‹œ ë²„í¼ë§í•  ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 1)"
    )
    parser.add_argument(
        "--stream-commit-size",
        type=int,
        default=None,
        help="TimescaleDB ìŠ¤íŠ¸ë¦¬ë° ì‹œ ì»¤ë°‹ ê°„ê²© ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸ê°’: ë²„í¼ í¬ê¸°)"
    )
    parser.add_argument(
        "--stream-progress-every",
        type=int,
        default=5000,
        help="ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ ìƒí™©ì„ ì¶œë ¥í•  ê°„ê²© (ê¸°ë³¸ê°’: 5000)"
    )
    parser.add_argument(
        "--skip-prometheus",
        action="store_true",
        help="Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹¤í–‰ì„ ìƒëµ"
    )
    return parser.parse_args()


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    args = parse_arguments()

    print("\n" + "="*80)
    print("ğŸ”¬ MongoDB vs TimescaleDB ì‹¤ì œ ì„±ëŠ¥ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("="*80)
    print("ì£¼ì˜: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¸¡ì •ê°’ë§Œ í‘œì‹œ")
    print("="*80)
    
    # Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘
    if args.skip_prometheus:
        print("\nâš ï¸  --skip-prometheus ì˜µì…˜ìœ¼ë¡œ ë©”íŠ¸ë¦­ ì„œë²„ ì‹¤í–‰ì„ ìƒëµí•©ë‹ˆë‹¤.")
    else:
        print(f"\nğŸ“Š Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘ (í¬íŠ¸ {METRICS_PORT})...")
        start_http_server(METRICS_PORT)
        print(f"âœ… ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘ ì™„ë£Œ: http://localhost:{METRICS_PORT}/metrics")
    
    # ì—°ê²°
    print("\nğŸ“¡ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
    db_mongo = connect_mongodb()
    conn_tsdb = connect_timescaledb()
    print("âœ… ì—°ê²° ì™„ë£Œ")
    
    try:
        print("\n" + "="*80)
        print("í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*80)

        mongo_write_results = tsdb_write_results = tsdb_read_results = mongo_read_results = None
        mongo_stream_results = tsdb_stream_results = None
        
        if args.mode in ("batch", "all"):
            print("\nâ–¶ï¸ ë°°ì¹˜ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
            mongo_write_results = test_mongodb_write_performance(db_mongo)
            tsdb_write_results = test_timescaledb_write_performance(conn_tsdb)
            tsdb_read_results = test_timescaledb_time_series_query_performance(conn_tsdb)
            mongo_read_results = test_mongodb_time_series_query_performance(db_mongo)
            print_comparison_summary(mongo_write_results, tsdb_write_results, tsdb_read_results, mongo_read_results)
        
        if args.mode in ("stream", "all"):
            print("\nâ–¶ï¸ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
            mongo_stream_results = test_mongodb_streaming_write_performance(
                db_mongo,
                total_records=args.stream_total_records,
                interval_ms=args.stream_interval_ms,
                jitter_ms=args.stream_jitter_ms,
                buffer_size=max(1, args.stream_buffer_size),
                progress_every=max(1, args.stream_progress_every)
            )
            tsdb_stream_results = test_timescaledb_streaming_write_performance(
                conn_tsdb,
                total_records=args.stream_total_records,
                interval_ms=args.stream_interval_ms,
                jitter_ms=args.stream_jitter_ms,
                buffer_size=max(1, args.stream_buffer_size),
                commit_size=args.stream_commit_size if args.stream_commit_size and args.stream_commit_size > 0 else None,
                progress_every=max(1, args.stream_progress_every)
            )
            print_streaming_comparison_summary(mongo_stream_results, tsdb_stream_results)
        
        print("\n" + "="*80)
        print("âœ… ì„ íƒí•œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print("="*80)

        if args.skip_prometheus:
            print("\nâ„¹ï¸  Prometheus ë©”íŠ¸ë¦­ ì„œë²„ë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        else:
            print(f"\nğŸ“Š Prometheus ë©”íŠ¸ë¦­ ì„œë²„ê°€ ê³„ì† ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            print(f"   ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸: http://localhost:{METRICS_PORT}/metrics")
            print(f"   Grafana ëŒ€ì‹œë³´ë“œ: http://localhost:3000")
            print(f"   Prometheus UI: http://localhost:9090")
            print(f"\nâš ï¸  ë©”íŠ¸ë¦­ ì„œë²„ë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")
            
            # ë©”íŠ¸ë¦­ ì„œë²„ë¥¼ ê³„ì† ì‹¤í–‰í•˜ë„ë¡ ëŒ€ê¸°
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                print("\n\nâœ… ë©”íŠ¸ë¦­ ì„œë²„ ì¢…ë£Œ")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    finally:
        conn_tsdb.close()

if __name__ == "__main__":
    main()
