#!/usr/bin/env python3
"""
MongoDB vs TimescaleDB ì‹¤ì œ ì„±ëŠ¥ ê²€ì¦ í…ŒìŠ¤íŠ¸
- ë°ì´í„°ì— ê¸°ë°˜í•œ ì‹¤ì œ ì¸¡ì •ê°’ë§Œ í‘œì‹œ
- ì¢‹ê²Œ í¬ì¥í•˜ì§€ ì•Šê³  ì‹¤ì œ ê²°ê³¼ë§Œ ì œì‹œ
- Prometheus ë©”íŠ¸ë¦­ export ì§€ì›
"""

import sys
import os
import time
from pymongo import MongoClient
import psycopg2
from datetime import datetime, timedelta
import random
from prometheus_client import start_http_server, Gauge, Histogram

# MongoDB ì—°ê²°
MONGO_HOST = os.getenv("MONGO_HOST", "localhost")
MONGO_PORT = int(os.getenv("MONGO_PORT", "27017"))
MONGO_DB = os.getenv("MONGO_DB", "alcha_events")

# TimescaleDB ì—°ê²°
TIMESCALEDB_HOST = os.getenv("TIMESCALEDB_HOST", "localhost")
TIMESCALEDB_PORT = int(os.getenv("TIMESCALEDB_PORT", "5432"))
TIMESCALEDB_DB = os.getenv("TIMESCALEDB_DB", "alcha_events")
TIMESCALEDB_USER = os.getenv("TIMESCALEDB_USER", "alcha")
TIMESCALEDB_PASSWORD = os.getenv("TIMESCALEDB_PASSWORD", "alcha_password")

# Prometheus ë©”íŠ¸ë¦­ ì„¤ì •
METRICS_PORT = int(os.getenv("METRICS_PORT", "8000"))

# Prometheus ë©”íŠ¸ë¦­ ì •ì˜
db_write_records_per_second = Gauge(
    'db_write_records_per_second',
    'ì´ˆë‹¹ ì“°ê¸° ì²˜ë¦¬ ë ˆì½”ë“œ ìˆ˜',
    ['db', 'batch_size']
)

db_write_time_seconds = Histogram(
    'db_write_time_seconds',
    'ì“°ê¸° ì‘ì—… ì†Œìš” ì‹œê°„ (ì´ˆ)',
    ['db', 'batch_size'],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0]
)

db_read_query_time_seconds = Histogram(
    'db_read_query_time_seconds',
    'ì½ê¸° ì¿¼ë¦¬ ì†Œìš” ì‹œê°„ (ì´ˆ)',
    ['db', 'query_type'],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
)

db_read_query_time_gauge = Gauge(
    'db_read_query_time_gauge_seconds',
    'ì½ê¸° ì¿¼ë¦¬ ì†Œìš” ì‹œê°„ (ì´ˆ) - ê²Œì´ì§€',
    ['db', 'query_type']
)

def connect_mongodb():
    """MongoDB ì—°ê²°"""
    uri = f"mongodb://{MONGO_HOST}:{MONGO_PORT}/"
    client = MongoClient(uri)
    return client[MONGO_DB]

def connect_timescaledb():
    """TimescaleDB ì—°ê²°"""
    conn = psycopg2.connect(
        host=TIMESCALEDB_HOST,
        port=TIMESCALEDB_PORT,
        database=TIMESCALEDB_DB,
        user=TIMESCALEDB_USER,
        password=TIMESCALEDB_PASSWORD
    )
    return conn

def test_mongodb_write_performance(db_mongo):
    """í…ŒìŠ¤íŠ¸ 1: MongoDB ì“°ê¸° ì„±ëŠ¥ ê²€ì¦"""
    print("\n" + "="*80)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 1: MongoDB ì“°ê¸° ì„±ëŠ¥ ê²€ì¦")
    print("="*80)
    print("ëª©ì : MongoDBë¥¼ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ì´ìœ ì¸ ë¹ ë¥¸ ì“°ê¸° ì†ë„ ê²€ì¦")
    print("-"*80)
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    test_collection = "write_performance_test"
    db_mongo[test_collection].drop()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (432,000ê°œ ë ˆì½”ë“œ)
    test_data = []
    base_time = datetime(2025, 9, 23, 1, 54, 26)
    for i in range(432000):
        test_data.append({
            "vehicle_id": f"VHC-{random.randint(1, 10):03d}",
            "vehicle_speed": random.uniform(20, 120),
            "engine_rpm": random.randint(800, 6000),
            "throttle_position": random.uniform(0, 100),
            "timestamp": (base_time + timedelta(seconds=i)).strftime('%Y-%m-%dT%H:%M:%SZ'),
            "sensor_data": {
                "temperature": random.uniform(20, 100),
                "pressure": random.uniform(10, 50),
                "additional_field_1": f"value_{i}",
                "additional_field_2": random.randint(1, 1000),
                "nested_data": {
                    "x": random.uniform(-10, 10),
                    "y": random.uniform(-10, 10),
                    "z": random.uniform(8, 12)
                }
            }
        })
    
    # ë°°ì¹˜ ì“°ê¸° í…ŒìŠ¤íŠ¸
    batch_sizes = [1000, 10000, 50000, 100000]
    
    print(f"\ní…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê°œ ë ˆì½”ë“œ ì¤€ë¹„ ì™„ë£Œ")
    print(f"ë°°ì¹˜ í¬ê¸°ë³„ ì“°ê¸° ì„±ëŠ¥ ì¸¡ì •:\n")
    
    results = []
    for batch_size in batch_sizes:
        db_mongo[test_collection].drop()  # ì´ˆê¸°í™”
        batches = [test_data[i:i+batch_size] for i in range(0, len(test_data), batch_size)]
        
        total_time = 0
        total_inserted = 0
        
        print(f"  ë°°ì¹˜ í¬ê¸° {batch_size}:")
        print(f"    ë°°ì¹˜ ê°œìˆ˜: {len(batches)}ê°œ, ë°°ì¹˜ë‹¹ í‰ê·  ë ˆì½”ë“œ: {len(test_data) // len(batches)}ê°œ")
        
        for batch_idx, batch in enumerate(batches):
            start = time.time()
            result = db_mongo[test_collection].insert_many(batch)
            elapsed = time.time() - start
            total_time += elapsed
            total_inserted += len(result.inserted_ids)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ (í° ë°°ì¹˜ì˜ ê²½ìš°)
            if batch_size >= 10000:
                if (batch_idx + 1) % max(1, len(batches) // 20) == 0 or (batch_idx + 1) == len(batches):
                    print(f"      ì§„í–‰: {batch_idx + 1}/{len(batches)} ë°°ì¹˜ ì™„ë£Œ... ({batch_idx * batch_size}/{len(test_data)} ë ˆì½”ë“œ)")
        
        records_per_second = total_inserted / total_time
        avg_time_per_batch = total_time / len(batches)
        
        results.append({
            'batch_size': batch_size,
            'total_records': total_inserted,
            'total_time': total_time,
            'records_per_second': records_per_second,
            'avg_time_per_batch': avg_time_per_batch
        })
        
        print(f"    ê²°ê³¼:")
        print(f"      - ì´ ë ˆì½”ë“œ: {total_inserted}ê°œ")
        print(f"      - ì´ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time*1000:.2f}ms)")
        print(f"      - ì´ˆë‹¹ ì²˜ë¦¬: {records_per_second:.0f} ë ˆì½”ë“œ/ì´ˆ")
        print(f"      - ë°°ì¹˜ë‹¹ í‰ê· : {avg_time_per_batch:.2f}ì´ˆ ({avg_time_per_batch*1000:.2f}ms)")
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        db_write_records_per_second.labels(db='mongodb', batch_size=str(batch_size)).set(records_per_second)
        db_write_time_seconds.labels(db='mongodb', batch_size=str(batch_size)).observe(total_time)
    
    # ìµœì  ë°°ì¹˜ í¬ê¸°
    best = max(results, key=lambda x: x['records_per_second'])
    print(f"\nìµœì  ì„±ëŠ¥:")
    print(f"  ë°°ì¹˜ í¬ê¸°: {best['batch_size']}")
    print(f"  ì´ˆë‹¹ ì²˜ë¦¬: {best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    
    return results

def test_timescaledb_write_performance(conn_tsdb):
    """í…ŒìŠ¤íŠ¸ 2: TimescaleDB ì“°ê¸° ì„±ëŠ¥ ê²€ì¦"""
    print("\n" + "="*80)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 2: TimescaleDB ì“°ê¸° ì„±ëŠ¥ ê²€ì¦")
    print("="*80)
    print("ëª©ì : TimescaleDBì˜ ì“°ê¸° ì„±ëŠ¥ ì¸¡ì • ë° MongoDBì™€ ë¹„êµ")
    print("-"*80)
    
    cursor = conn_tsdb.cursor()
    
    # í…ŒìŠ¤íŠ¸ í…Œì´ë¸” ìƒì„±
    cursor.execute("""
        DROP TABLE IF EXISTS write_performance_test CASCADE;
    """)
    cursor.execute("""
        CREATE TABLE write_performance_test (
            vehicle_id VARCHAR(50) NOT NULL,
            vehicle_speed FLOAT,
            engine_rpm INTEGER,
            throttle_position FLOAT,
            timestamp TIMESTAMPTZ NOT NULL
        );
    """)
    cursor.execute("SELECT create_hypertable('write_performance_test', 'timestamp', if_not_exists => TRUE);")
    conn_tsdb.commit()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (432,000ê°œ ë ˆì½”ë“œ)
    test_data = []
    base_time = datetime(2025, 9, 23, 1, 54, 26)
    for i in range(432000):
        test_data.append((
            f"VHC-{random.randint(1, 10):03d}",
            random.uniform(20, 120),
            random.randint(800, 6000),
            random.uniform(0, 100),
            (base_time + timedelta(seconds=i)).strftime('%Y-%m-%dT%H:%M:%SZ')
        ))
    
    # ë°°ì¹˜ ì“°ê¸° í…ŒìŠ¤íŠ¸
    batch_sizes = [1000, 10000, 50000, 100000]
    
    print(f"\ní…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê°œ ë ˆì½”ë“œ ì¤€ë¹„ ì™„ë£Œ")
    print(f"ë°°ì¹˜ í¬ê¸°ë³„ ì“°ê¸° ì„±ëŠ¥ ì¸¡ì •:\n")
    
    results = []
    for batch_size in batch_sizes:
        cursor.execute("DELETE FROM write_performance_test;")
        conn_tsdb.commit()
        
        batches = [test_data[i:i+batch_size] for i in range(0, len(test_data), batch_size)]
        
        total_time = 0
        total_inserted = 0
        
        print(f"  ë°°ì¹˜ í¬ê¸° {batch_size}:")
        print(f"    ë°°ì¹˜ ê°œìˆ˜: {len(batches)}ê°œ, ë°°ì¹˜ë‹¹ í‰ê·  ë ˆì½”ë“œ: {len(test_data) // len(batches)}ê°œ")
        
        for batch_idx, batch in enumerate(batches):
            start = time.time()
            cursor.executemany("""
                INSERT INTO write_performance_test (vehicle_id, vehicle_speed, engine_rpm, throttle_position, timestamp)
                VALUES (%s, %s, %s, %s, %s)
            """, batch)
            conn_tsdb.commit()
            elapsed = time.time() - start
            total_time += elapsed
            total_inserted += len(batch)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ (í° ë°°ì¹˜ì˜ ê²½ìš°)
            if batch_size >= 10000:
                if (batch_idx + 1) % max(1, len(batches) // 20) == 0 or (batch_idx + 1) == len(batches):
                    print(f"      ì§„í–‰: {batch_idx + 1}/{len(batches)} ë°°ì¹˜ ì™„ë£Œ... ({batch_idx * batch_size}/{len(test_data)} ë ˆì½”ë“œ)")
        
        records_per_second = total_inserted / total_time
        avg_time_per_batch = total_time / len(batches)
        
        results.append({
            'batch_size': batch_size,
            'total_records': total_inserted,
            'total_time': total_time,
            'records_per_second': records_per_second,
            'avg_time_per_batch': avg_time_per_batch
        })
        
        print(f"    ê²°ê³¼:")
        print(f"      - ì´ ë ˆì½”ë“œ: {total_inserted}ê°œ")
        print(f"      - ì´ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time*1000:.2f}ms)")
        print(f"      - ì´ˆë‹¹ ì²˜ë¦¬: {records_per_second:.0f} ë ˆì½”ë“œ/ì´ˆ")
        print(f"      - ë°°ì¹˜ë‹¹ í‰ê· : {avg_time_per_batch:.2f}ì´ˆ ({avg_time_per_batch*1000:.2f}ms)")
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        db_write_records_per_second.labels(db='timescaledb', batch_size=str(batch_size)).set(records_per_second)
        db_write_time_seconds.labels(db='timescaledb', batch_size=str(batch_size)).observe(total_time)
    
    # ìµœì  ë°°ì¹˜ í¬ê¸°
    best = max(results, key=lambda x: x['records_per_second'])
    print(f"\nìµœì  ì„±ëŠ¥:")
    print(f"  ë°°ì¹˜ í¬ê¸°: {best['batch_size']}")
    print(f"  ì´ˆë‹¹ ì²˜ë¦¬: {best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    
    cursor.close()
    return results

def test_timescaledb_time_series_query_performance(conn_tsdb):
    """í…ŒìŠ¤íŠ¸ 3: TimescaleDB ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦"""
    print("\n" + "="*80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ 3: TimescaleDB ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦")
    print("="*80)
    print("ëª©ì : TimescaleDBë¥¼ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ì´ìœ ì¸ ì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥ ê²€ì¦")
    print("-"*80)
    
    cursor = conn_tsdb.cursor()
    
    # ì‹¤ì œ ë°ì´í„° ê¸°ì¤€ í…ŒìŠ¤íŠ¸
    vehicle_ids = ["VHC-001", "VHC-002", "VHC-003"]
    
    tests = [
        {
            "name": "ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)",
            "query": """
                SELECT vehicle_id, vehicle_speed, engine_rpm, throttle_position, timestamp
                FROM vehicle_telemetry
                WHERE vehicle_id = %s 
                  AND timestamp >= %s 
                  AND timestamp <= %s
                ORDER BY timestamp ASC
            """,
            "params": lambda vid: (vid, "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        },
        {
            "name": "ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)",
            "query": """
                SELECT 
                    COUNT(*) as count,
                    AVG(vehicle_speed) as avg_speed,
                    MAX(vehicle_speed) as max_speed,
                    MIN(vehicle_speed) as min_speed,
                    AVG(engine_rpm) as avg_rpm,
                    MAX(engine_rpm) as max_rpm,
                    MIN(engine_rpm) as min_rpm
                FROM vehicle_telemetry
                WHERE vehicle_id = %s 
                  AND timestamp >= %s 
                  AND timestamp <= %s
            """,
            "params": lambda vid: (vid, "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        },
        {
            "name": "ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)",
            "query": """
                SELECT 
                    time_bucket('10 minutes', timestamp) as bucket,
                    AVG(vehicle_speed) as avg_speed,
                    COUNT(*) as count
                FROM vehicle_telemetry
                WHERE vehicle_id = %s 
                  AND timestamp >= %s 
                  AND timestamp <= %s
                GROUP BY bucket
                ORDER BY bucket ASC
            """,
            "params": lambda vid: (vid, "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        },
        {
            "name": "ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (1ë¶„ ë‹¨ìœ„)",
            "query": """
                SELECT 
                    time_bucket('1 minute', timestamp) as bucket,
                    AVG(vehicle_speed) as avg_speed,
                    COUNT(*) as count
                FROM vehicle_telemetry
                WHERE vehicle_id = %s 
                  AND timestamp >= %s 
                  AND timestamp <= %s
                GROUP BY bucket
                ORDER BY bucket ASC
            """,
            "params": lambda vid: (vid, "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        },
        {
            "name": "ë³µì¡í•œ ì‹œê°„ ë²”ìœ„ ì§‘ê³„ (ë‹¤ì¤‘ ì°¨ëŸ‰)",
            "query": """
                SELECT 
                    vehicle_id,
                    time_bucket('5 minutes', timestamp) as bucket,
                    AVG(vehicle_speed) as avg_speed,
                    MAX(vehicle_speed) as max_speed,
                    COUNT(*) as count
                FROM vehicle_telemetry
                WHERE vehicle_id IN (%s, %s, %s)
                  AND timestamp >= %s 
                  AND timestamp <= %s
                GROUP BY vehicle_id, bucket
                ORDER BY vehicle_id, bucket ASC
            """,
            "params": lambda vid: ("VHC-001", "VHC-002", "VHC-003", "2025-09-23T01:54:26Z", "2025-09-24T17:54:26Z")  # 40ì‹œê°„ ë²”ìœ„
        }
    ]
    
    print(f"\nì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • (ê° í…ŒìŠ¤íŠ¸ 10íšŒ ë°˜ë³µ, í‰ê· ê°’ ì‚¬ìš©):\n")
    
    results = []
    for test in tests:
        times = []
        for _ in range(10):
            start = time.time()
            if "vehicle_id IN" in test["query"]:
                cursor.execute(test["query"], test["params"](None))
            else:
                cursor.execute(test["query"], test["params"]("VHC-001"))
            cursor.fetchall()
            times.append(time.time() - start)
        
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        # ê²°ê³¼ ê°œìˆ˜ í™•ì¸ (í•œ ë²ˆë§Œ ì‹¤í–‰)
        if "vehicle_id IN" in test["query"]:
            cursor.execute(test["query"], test["params"](None))
        else:
            cursor.execute(test["query"], test["params"]("VHC-001"))
        result_count = len(cursor.fetchall())
        
        results.append({
            'name': test['name'],
            'avg_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'result_count': result_count
        })
        
        print(f"  {test['name']}:")
        print(f"    - í‰ê·  ì‹œê°„: {avg_time*1000:.2f}ms")
        print(f"    - ìµœì†Œ ì‹œê°„: {min_time*1000:.2f}ms")
        print(f"    - ìµœëŒ€ ì‹œê°„: {max_time*1000:.2f}ms")
        print(f"    - ê²°ê³¼ ê°œìˆ˜: {result_count}ê°œ")
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        query_type_map = {
            'ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)': 'time_range',
            'ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)': 'aggregation',
            'ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)': 'time_grouping_10min',
            'ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (1ë¶„ ë‹¨ìœ„)': 'time_grouping_1min',
            'ë³µì¡í•œ ì‹œê°„ ë²”ìœ„ ì§‘ê³„ (ë‹¤ì¤‘ ì°¨ëŸ‰)': 'multi_vehicle_aggregation'
        }
        query_type = query_type_map.get(test['name'], 'unknown')
        
        for time_val in times:
            db_read_query_time_seconds.labels(db='timescaledb', query_type=query_type).observe(time_val)
        db_read_query_time_gauge.labels(db='timescaledb', query_type=query_type).set(avg_time)
    
    cursor.close()
    return results

def test_mongodb_time_series_query_performance(db_mongo):
    """í…ŒìŠ¤íŠ¸ 4: MongoDB ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦ (ë¹„êµìš©)"""
    print("\n" + "="*80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ 4: MongoDB ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦ (ë¹„êµìš©)")
    print("="*80)
    print("ëª©ì : MongoDBì˜ ì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • ë° TimescaleDBì™€ ë¹„êµ")
    print("-"*80)
    
    vehicle_id = "VHC-001"
    start_time = "2025-09-23T01:54:26Z"
    end_time = "2025-09-24T17:54:26Z"  # 40ì‹œê°„ í›„
    
    tests = [
        {
            "name": "ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)",
            "operation": lambda: list(db_mongo["realtime-storage-data"].find({
                "vehicle_id": vehicle_id,
                "timestamp": {"$gte": start_time, "$lte": end_time}
            }).sort("timestamp", 1))
        },
        {
            "name": "ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)",
            "operation": lambda: list(db_mongo["realtime-storage-data"].aggregate([
                {"$match": {
                    "vehicle_id": vehicle_id,
                    "timestamp": {"$gte": start_time, "$lte": end_time}
                }},
                {"$group": {
                    "_id": None,
                    "avg_speed": {"$avg": "$vehicle_speed"},
                    "max_speed": {"$max": "$vehicle_speed"},
                    "min_speed": {"$min": "$vehicle_speed"},
                    "avg_rpm": {"$avg": "$engine_rpm"},
                    "max_rpm": {"$max": "$engine_rpm"},
                    "min_rpm": {"$min": "$engine_rpm"},
                    "count": {"$sum": 1}
                }}
            ]))
        },
        {
            "name": "ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)",
            "operation": lambda: list(db_mongo["realtime-storage-data"].aggregate([
                {"$match": {
                    "vehicle_id": vehicle_id,
                    "timestamp": {"$gte": start_time, "$lte": end_time}
                }},
                {"$addFields": {
                    "timestamp_iso": {"$dateFromString": {"dateString": "$timestamp"}}
                }},
                {"$group": {
                    "_id": {
                        "$dateTrunc": {
                            "date": "$timestamp_iso",
                            "unit": "minute",
                            "binSize": 10
                        }
                    },
                    "avg_speed": {"$avg": "$vehicle_speed"},
                    "count": {"$sum": 1}
                }},
                {"$sort": {"_id": 1}}
            ]))
        }
    ]
    
    print(f"\nì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • (ê° í…ŒìŠ¤íŠ¸ 10íšŒ ë°˜ë³µ, í‰ê· ê°’ ì‚¬ìš©):\n")
    
    results = []
    for test in tests:
        times = []
        for _ in range(10):
            start = time.time()
            result = test["operation"]()
            times.append(time.time() - start)
        
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        result_count = len(result)
        
        results.append({
            'name': test['name'],
            'avg_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'result_count': result_count
        })
        
        print(f"  {test['name']}:")
        print(f"    - í‰ê·  ì‹œê°„: {avg_time*1000:.2f}ms")
        print(f"    - ìµœì†Œ ì‹œê°„: {min_time*1000:.2f}ms")
        print(f"    - ìµœëŒ€ ì‹œê°„: {max_time*1000:.2f}ms")
        print(f"    - ê²°ê³¼ ê°œìˆ˜: {result_count}ê°œ")
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        query_type_map = {
            'ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)': 'time_range',
            'ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)': 'aggregation',
            'ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)': 'time_grouping_10min'
        }
        query_type = query_type_map.get(test['name'], 'unknown')
        
        for time_val in times:
            db_read_query_time_seconds.labels(db='mongodb', query_type=query_type).observe(time_val)
        db_read_query_time_gauge.labels(db='mongodb', query_type=query_type).set(avg_time)
    
    return results

def print_comparison_summary(mongo_write, tsdb_write, tsdb_read, mongo_read):
    """ë¹„êµ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“Š ì¢…í•© ë¹„êµ ìš”ì•½")
    print("="*80)
    
    # ì“°ê¸° ì„±ëŠ¥ ë¹„êµ
    mongo_best = max(mongo_write, key=lambda x: x['records_per_second'])
    tsdb_best = max(tsdb_write, key=lambda x: x['records_per_second'])
    
    print(f"\n1. ì“°ê¸° ì„±ëŠ¥ (ìµœì  ë°°ì¹˜ í¬ê¸° ê¸°ì¤€):")
    print(f"   MongoDB:")
    print(f"     - ì´ˆë‹¹ ì²˜ë¦¬: {mongo_best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"     - ë°°ì¹˜ í¬ê¸°: {mongo_best['batch_size']}")
    print(f"   TimescaleDB:")
    print(f"     - ì´ˆë‹¹ ì²˜ë¦¬: {tsdb_best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"     - ë°°ì¹˜ í¬ê¸°: {tsdb_best['batch_size']}")
    
    if mongo_best['records_per_second'] > tsdb_best['records_per_second']:
        diff = (mongo_best['records_per_second'] / tsdb_best['records_per_second'] - 1) * 100
        print(f"   â†’ MongoDBê°€ {diff:.1f}% ë¹ ë¦„")
    else:
        diff = (tsdb_best['records_per_second'] / mongo_best['records_per_second'] - 1) * 100
        print(f"   â†’ TimescaleDBê°€ {diff:.1f}% ë¹ ë¦„")
    
    # ì½ê¸° ì„±ëŠ¥ ë¹„êµ (ë™ì¼í•œ ì¿¼ë¦¬ë§Œ ë¹„êµ)
    print(f"\n2. ì‹œê³„ì—´ ì½ê¸° ì„±ëŠ¥ (í‰ê· ê°’ ê¸°ì¤€):")
    
    common_tests = [
        ("ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬", "ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬ (40ì‹œê°„ ë°ì´í„°)"),
        ("ì§‘ê³„ ì¿¼ë¦¬", "ì§‘ê³„ ì¿¼ë¦¬ (í‰ê· /ìµœëŒ€/ìµœì†Œ)"),
        ("ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™”", "ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í™” (10ë¶„ ë‹¨ìœ„)")
    ]
    
    for test_name, mongo_key in common_tests:
        mongo_test = next((t for t in mongo_read if mongo_key in t['name']), None)
        tsdb_test = next((t for t in tsdb_read if test_name in t['name'] or mongo_key in t['name']), None)
        
        if mongo_test and tsdb_test:
            print(f"\n   {test_name}:")
            print(f"     - MongoDB: {mongo_test['avg_time']*1000:.2f}ms")
            print(f"     - TimescaleDB: {tsdb_test['avg_time']*1000:.2f}ms")
            if mongo_test['avg_time'] > tsdb_test['avg_time']:
                diff = (mongo_test['avg_time'] / tsdb_test['avg_time'] - 1) * 100
                print(f"     â†’ TimescaleDBê°€ {diff:.1f}% ë¹ ë¦„")
            else:
                diff = (tsdb_test['avg_time'] / mongo_test['avg_time'] - 1) * 100
                print(f"     â†’ MongoDBê°€ {diff:.1f}% ë¹ ë¦„")
    
    print(f"\n3. ê²°ë¡ :")
    print(f"   - MongoDB ì“°ê¸°: {mongo_best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"   - TimescaleDB ì“°ê¸°: {tsdb_best['records_per_second']:.0f} ë ˆì½”ë“œ/ì´ˆ")
    print(f"   - ì‹œê³„ì—´ ì¿¼ë¦¬: ì‹¤ì œ ì¸¡ì •ê°’ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("\n" + "="*80)
    print("ğŸ”¬ MongoDB vs TimescaleDB ì‹¤ì œ ì„±ëŠ¥ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("="*80)
    print("ì£¼ì˜: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¸¡ì •ê°’ë§Œ í‘œì‹œ")
    print("="*80)
    
    # Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘
    print(f"\nğŸ“Š Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘ (í¬íŠ¸ {METRICS_PORT})...")
    start_http_server(METRICS_PORT)
    print(f"âœ… ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘ ì™„ë£Œ: http://localhost:{METRICS_PORT}/metrics")
    
    # ì—°ê²°
    print("\nğŸ“¡ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
    db_mongo = connect_mongodb()
    conn_tsdb = connect_timescaledb()
    print("âœ… ì—°ê²° ì™„ë£Œ")
    
    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        print("\n" + "="*80)
        print("í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*80)
        
        mongo_write_results = test_mongodb_write_performance(db_mongo)
        tsdb_write_results = test_timescaledb_write_performance(conn_tsdb)
        tsdb_read_results = test_timescaledb_time_series_query_performance(conn_tsdb)
        mongo_read_results = test_mongodb_time_series_query_performance(db_mongo)
        
        # ë¹„êµ ìš”ì•½
        print_comparison_summary(mongo_write_results, tsdb_write_results, tsdb_read_results, mongo_read_results)
        
        print("\n" + "="*80)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print("="*80)
        print(f"\nğŸ“Š Prometheus ë©”íŠ¸ë¦­ ì„œë²„ê°€ ê³„ì† ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
        print(f"   ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸: http://localhost:{METRICS_PORT}/metrics")
        print(f"   Grafana ëŒ€ì‹œë³´ë“œ: http://localhost:3000")
        print(f"   Prometheus UI: http://localhost:9090")
        print(f"\nâš ï¸  ë©”íŠ¸ë¦­ ì„œë²„ë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")
        
        # ë©”íŠ¸ë¦­ ì„œë²„ë¥¼ ê³„ì† ì‹¤í–‰í•˜ë„ë¡ ëŒ€ê¸°
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\n\nâœ… ë©”íŠ¸ë¦­ ì„œë²„ ì¢…ë£Œ")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    finally:
        conn_tsdb.close()

if __name__ == "__main__":
    main()
